{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "868db98c-9362-41ab-b6e2-82713592c24f",
   "metadata": {},
   "source": [
    "Note: Before running this notebook download dataset from https://github.com/Armin1337/RebarDSC into your project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaebfe8-517a-4be1-a8de-81fbf3c0c495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Dependencies\n",
    "\n",
    "%pip install torch==2.2.0 torchvision==0.17.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "%pip install opencv-python\n",
    "%pip install pycocotools\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110c851-6518-4c7c-aaea-0050eeb2a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import cv2\n",
    "import engine\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pycocotools.cocoeval\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import torchvision\n",
    "from engine import train_one_epoch, evaluate\n",
    "from importlib import reload\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "os.system(\"curl https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py -o engine.py\")\n",
    "os.system(\"curl https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py -o utils.py\")\n",
    "os.system(\"curl https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py -o coco_utils.py\")\n",
    "os.system(\"curl https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py -o coco_eval.py\")\n",
    "os.system(\"curl https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py -o transforms.py\")\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "MODEL_DIR = \"./model\"\n",
    "DATASET_DIR = \"./RebarDSC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c215a9-1bc8-477d-8122-ca9a819b83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show single image with annotations to check\n",
    "\n",
    "key = \"861_20MM\"\n",
    "train_df = pd.read_csv(f\"{DATASET_DIR}/annotations/100_percent_train.csv\", header=None)\n",
    "train_df = train_df[train_df[0] == f\"rebar_{key}.jpg\"]\n",
    "str_boxes = train_df[1].values.flatten().tolist()\n",
    "img = Image.open(f\"{DATASET_DIR}/images/rebar_{key}.jpg\").convert('RGB')\n",
    "pyplot.figure(figsize=(img.size[0]/400.0, img.size[1]/400.0))\n",
    "img = np.array(img)\n",
    "for str_box in str_boxes:\n",
    "  xmin, ymin, xmax, ymax = [int(c) for c in str_box.split()]  \n",
    "  cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 4)\n",
    "pyplot.imshow(img)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1fb26-a0ae-4c06-b155-4873638afa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "\n",
    "class RebarDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "  def __init__(self, csv_path, transforms=None):                \n",
    "    self.df = pd.read_csv(csv_path, header=None)\n",
    "    self.imgs = self.df[0].unique().flatten().tolist()\n",
    "    self.transforms = transforms        \n",
    "\n",
    "  def __getitem__(self, idx):                \n",
    "    img = Image.open(f\"{DATASET_DIR}/images/{self.imgs[idx]}\").convert(\"RGB\")\n",
    "    str_boxes = self.df[self.df[0] == self.imgs[idx]][1].values.flatten().tolist()\n",
    "    float_boxes = []\n",
    "    for str_box in str_boxes:\n",
    "      b = [int(c) for c in str_box.split()]\n",
    "      if b[0] < b[2] and b[1] < b[3]:\n",
    "        float_boxes.append(b)    \n",
    "    boxes = torch.as_tensor(float_boxes, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    target = {}\n",
    "    target[\"image_id\"] = idx\n",
    "    target[\"boxes\"] = boxes\n",
    "    target[\"labels\"] = torch.ones((len(boxes),), dtype=torch.int64 , device=DEVICE)    \n",
    "    target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "    target[\"iscrowd\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "\n",
    "    if self.transforms:\n",
    "      img, target = self.transforms(img, target)\n",
    "\n",
    "    return img, target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs)\n",
    "\n",
    "  def get_ids(self):\n",
    "    return [i for i in range(len(self.imgs))]    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910715d4-1370-438b-bd36-ce0ee3771b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders\n",
    "\n",
    "import transforms as T\n",
    "\n",
    "def get_transform(train):    \n",
    "  transforms = [T.PILToTensor(), T.ToDtype(torch.float, scale=True)]\n",
    "  if train:\n",
    "    transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "  return T.Compose(transforms)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_csv_path = f\"{DATASET_DIR}/annotations/100_percent_train.csv\"\n",
    "train_dataset = RebarDataset(train_csv_path, get_transform(True))\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, train_dataset.get_ids())\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "test_csv_path = f\"{DATASET_DIR}/annotations/test.csv\"\n",
    "test_dataset = RebarDataset(test_csv_path, get_transform(False))\n",
    "test_dataset = torch.utils.data.Subset(test_dataset, test_dataset.get_ids())\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2ec24-0bcb-41aa-a893-b6440e55323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "if os.path.exists(MODEL_DIR):\n",
    "  shutil.rmtree(MODEL_DIR)\n",
    "os.makedirs(MODEL_DIR)\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(\n",
    "    pretrained=True, progress=True)\n",
    "model.roi_heads.detections_per_img=1000\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "    model.roi_heads.box_predictor.cls_score.in_features, 2) \n",
    "model.to(DEVICE)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params, lr=3e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.06)\n",
    "\n",
    "for epoch in range(5):\n",
    "    train_one_epoch(model, optimizer, train_data_loader, DEVICE, epoch, print_freq=50)    \n",
    "    lr_scheduler.step()      \n",
    "    evaluate(model, test_data_loader, device=DEVICE)        \n",
    "    torch.save(model.cpu().state_dict(), f\"{MODEL_DIR}/model_{epoch}.pth\")\t\t \n",
    "    model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8616ee-d135-474a-8a0d-331fdaa86fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the results\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(\n",
    "    pretrained=True, progress=True)\n",
    "model.roi_heads.detections_per_img = 1000\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "    model.roi_heads.box_predictor.cls_score.in_features, 2) \n",
    "model.to(DEVICE)\n",
    "\n",
    "\n",
    "epoch = max(int(f.split(\"_\")[1].split(\".\")[0]) for f in os.listdir(MODEL_DIR))\n",
    "model.load_state_dict(torch.load(f\"{MODEL_DIR}/model_{epoch}.pth\"))\n",
    "model.eval()\n",
    "\n",
    "df = pd.read_csv(f\"{DATASET_DIR}/annotations/test.csv\", header=None)\n",
    "img_list = df[0].unique().flatten().tolist()\n",
    "random.shuffle(img_list)\n",
    "\n",
    "for i, name in enumerate(img_list[:5]):\n",
    "    str_boxes = df[df[0] == name][1].values.flatten().tolist()\n",
    "    boxes = []\n",
    "    for str_box in str_boxes:\n",
    "      b = [int(c) for c in str_box.split()]\n",
    "      if b[0] < b[2] and b[1] < b[3]:\n",
    "        boxes.append(b)\n",
    "    \n",
    "    image_src = Image.open(f\"{DATASET_DIR}/images/{name}\").convert(\"RGB\")\n",
    "    img_tensor = torchvision.transforms.ToTensor()(image_src)\n",
    "    result_dict = None\n",
    "    with torch.no_grad():      \n",
    "      img = np.array(image_src.copy())\n",
    "      for xmin, ymin, xmax, ymax in boxes: \n",
    "        cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 4)\n",
    "      \n",
    "      result_dict = model([img_tensor.to(DEVICE)])\n",
    "      bbox = result_dict[0][\"boxes\"].cpu().numpy()\n",
    "      scores = result_dict[0][\"scores\"].cpu().numpy()         \n",
    "      rebar_count = 0     \n",
    "      for bbox, score in zip(bbox, scores):\n",
    "        if len(bbox) > 0 and score > 0.75:          \n",
    "          rebar_count += 1\n",
    "          cv2.circle(img,\n",
    "                     (int((bbox[0] + bbox[2]) * 0.5), int((bbox[1] + bbox[3]) * 0.5)),\n",
    "                     int((bbox[2] - bbox[0]) * 0.5 * 0.6),\n",
    "                     (255, 0, 0),\n",
    "                     -1)          \n",
    "      \n",
    "      print(\"Rebar count:\", rebar_count, f\"(red circles) vs {len(boxes)} expected (green boxes)\")\n",
    "      pyplot.figure(i, figsize=(10, 10))\n",
    "      pyplot.imshow(img)\n",
    "      pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
